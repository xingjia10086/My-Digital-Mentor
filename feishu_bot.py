import os
import json
import re
import logging
import threading
import feedparser
from dotenv import load_dotenv
import lark_oapi as lark
from lark_oapi.api.im.v1 import *
from google import genai
from langchain_google_vertexai import VertexAIEmbeddings
from langchain_community.vectorstores import Chroma
import vertexai
from vertexai.preview.vision_models import ImageGenerationModel

load_dotenv()

# --- Configuration ---
FEISHU_APP_ID = os.environ.get("FEISHU_APP_ID", "")
FEISHU_APP_SECRET = os.environ.get("FEISHU_APP_SECRET", "")

PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "")
LOCATION = os.environ.get("GCP_LOCATION", "us-central1")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHROMA_PERSIST_DIR = os.path.join(BASE_DIR, "chroma_db")
EMBEDDING_MODEL = "text-embedding-004"
API_KEY = os.environ.get("GOOGLE_API_KEY", "")

MODEL_NAME = "gemini-2.5-pro"  

print("=== åˆå§‹åŒ– æ˜Ÿä½³æ•°å­—å¯¼å¸ˆ (è§†è§‰åˆ†å‘çŸ©é˜µå‡çº§ç‰ˆ) ===")
print("æ­£åœ¨è¿æ¥ Google Gemini å’Œæœ¬åœ° ChromaDB çŸ¥è¯†åº“...")
genai_client = genai.Client(api_key=API_KEY)
lark_client = lark.Client.builder().app_id(FEISHU_APP_ID).app_secret(FEISHU_APP_SECRET).build()

vertexai.init(project=PROJECT_ID, location=LOCATION)
# åˆå§‹åŒ– Google Imagen ç”»å›¾æ¨¡å‹ (å‡çº§åˆ°æœ€æ–°çš„ 002 ç‰ˆæœ¬)
try:
    from vertexai.preview.vision_models import ImageGenerationModel
    imagen_model = ImageGenerationModel.from_pretrained("imagen-3.0-generate-002")
except Exception as e:
    print(f"Imagen3 è½½å…¥å¤±è´¥: {e}")
    imagen_model = None

embeddings = VertexAIEmbeddings(
    model_name=EMBEDDING_MODEL,
    project=PROJECT_ID,
    location=LOCATION
)
vectorstore = Chroma(
    persist_directory=CHROMA_PERSIST_DIR,
    embedding_function=embeddings,
    collection_name="wechat_articles"
)

chat_histories = {}
MAX_HISTORY = 3

CACHE_FILE = os.path.join(BASE_DIR, "feishu_processed.json")
if os.path.exists(CACHE_FILE):
    try:
        with open(CACHE_FILE, "r") as f:
            processed_msg_ids = json.load(f)
    except:
        processed_msg_ids = []
else:
    processed_msg_ids = []
MAX_PROCESSED = 200

def save_cache():
    try:
        with open(CACHE_FILE, "w") as f:
            json.dump(processed_msg_ids, f)
    except:
        pass

def format_docs(docs):
    formatted = []
    for d in docs:
        source = d.metadata.get('source_file', 'æœªçŸ¥æ–‡ç« ')
        formatted.append(f"ã€æ‘˜è‡ªæ–‡ç« ï¼šã€Š{source}ã€‹ã€‘\n{d.page_content}")
    return "\n\n---\n\n".join(formatted)

def fetch_daily_news():
    feeds = {
        "36æ°ª (å•†ä¸šåˆ›æŠ•)": "https://36kr.com/feed",
        "Hacker News (å…¨çƒå‰æ²¿ç§‘æŠ€)": "https://news.ycombinator.com/rss",
        "V2EX (æå®¢çƒ­æ¦œ)": "https://www.v2ex.com/index.xml",
        "ReadHub (ç§‘æŠ€åŠ¨æ€)": "https://readhub.cn/rss",
        "åå°”è¡—è§é—» (å…¨çƒå®è§‚ä¸å¸‚åœº)": "https://wallstreetcn.com/rss/gold",
        "åå°”è¡—æ—¥æŠ¥ WSJ (æ¸¯ç¾è‚¡ä¸è´¢ç»)": "https://cn.wsj.com/zh-hans/rss",
        "FTä¸­æ–‡ç½‘ (é‡‘èæ—¶æŠ¥)": "https://www.ftchinese.com/rss/feed",
        "ç¬¬ä¸€è´¢ç» (å¤§é™†ä¸æ¸¯è‚¡ç›˜é¢)": "https://www.yicai.com/rss/news.xml"
    }
    news_text = ""
    for name, url in feeds.items():
        try:
            f = feedparser.parse(url)
            news_text += f"\nã€{name}ã€‘\n"
            for entry in f.entries[:5]: # ä»æ¯ä¸ªæºæŠ“å–å‰ 5 æ¡
                news_text += f"- {entry.title}\n"
        except Exception as e:
            pass
    return news_text

def process_message(sender_id, text, message_id):
    history = chat_histories.get(sender_id, [])
    if text.strip().lower() in ['clear', 'æ¸…é™¤è®°å¿†', 'æ¸…ç©ºè®°å¿†']:
        chat_histories[sender_id] = []
        reply_msg(message_id, "ğŸ§  å’”åš“ï¼æˆ‘å·²ç»æ¸…ç©ºäº†åˆšæ‰çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œè®©æˆ‘ä»¬å¼€å¯ä¸€ä¸ªå…¨æ–°çš„è¯é¢˜å§ã€‚")
        return
        
    is_xhs = False
    is_tiktok = False
    is_news = False
    actual_query = text
    
    if text.lower().startswith("/xhs "):
        is_xhs = True
        actual_query = text[5:].strip()
    elif text.lower().startswith("/tiktok "):
        is_tiktok = True
        actual_query = text[8:].strip()
    elif text.lower().strip() == "/news":
        is_news = True
        actual_query = "è¯·å¸®æˆ‘è§£è¯»ä»Šå¤©çš„ç§‘æŠ€å•†ä¸šæ™¨æŠ¥ã€‚"
    elif text.lower().startswith("/news "):
        is_news = True
        actual_query = text[6:].strip()
    
    search_query = actual_query
    if history and not (is_xhs or is_tiktok or is_news):
        search_query = f"å…³äº {history[-1]['q']} çš„è¿›ä¸€æ­¥æ¢è®¨: {actual_query}"
        
    print(f"\n[æ£€ç´¢æ„å›¾]: {search_query}")
    docs = vectorstore.similarity_search(search_query, k=6) 
    context_str = format_docs(docs)
    unique_sources = list(set([d.metadata.get('source_file', 'æœªçŸ¥') for d in docs]))
    
    history_str = ""
    if history and not (is_xhs or is_tiktok or is_news):
        history_str = "\nã€æœ€è¿‘çš„å¯¹è¯å†å²ã€‘ï¼š\n"
        for h in history:
            history_str += f"æ˜Ÿä½³: {h['q']}\nå¯¼å¸ˆ: {h['a'][:150]}...\n"
            
    if is_xhs:
        prompt = f"""ä½ æ˜¯æ˜Ÿä½³æ——ä¸‹çš„é‡‘ç‰Œå°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆæ“ç›˜æ‰‹ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æ·±æ²‰çš„å•†ä¸šæ€è€ƒé‡å¡‘ä¸ºé«˜èµã€é«˜æ”¶è—çš„å°çº¢ä¹¦å›¾æ–‡æ–‡æ¡ˆã€‚
è¯·åŸºäºä»¥ä¸‹æ˜Ÿä½³çš„ã€å†å²æ–‡ç« ç‰‡æ®µã€‘ï¼Œé’ˆå¯¹ç”¨æˆ·æå‡ºçš„ä¸»é¢˜ï¼šâ€œ{actual_query}â€ï¼Œå†™ä¸€ç¯‡å°çº¢ä¹¦å›¾æ–‡è„šæœ¬ã€‚

ã€éå¸¸é‡è¦ï¼šé…å›¾æŒ‡ä»¤ã€‘ï¼šåœ¨æ–‡æœ«ï¼Œè¯·åŠ¡å¿…ç”¨ç‰¹å®šçš„æ ‡ç­¾åŒ…å›´ä¸€æ®µçº¯è‹±æ–‡çš„ç”Ÿå›¾ Promptï¼Œè¿™ä¼šè®© AI ç”»å¸ˆç”Ÿæˆå°çº¢ä¹¦å°é¢å›¾ã€‚
**ä½ å¿…é¡»ç¡®ä¿è¿™å¼ å›¾æ˜¯å…¸å‹çš„é«˜è´¨é‡â€œå°çº¢ä¹¦çˆ†æ¬¾é£æ ¼â€**ï¼ˆä¾‹å¦‚ï¼šæç®€é«˜çº§æ„Ÿã€æ˜äº®æ²»æ„ˆç³»ã€å•†åŠ¡ç²¾è‹±æ¡Œé¢ã€æˆ–è€…ç²¾è‡´çš„å¹³é“ºæ‘†ä»¶ï¼‰ã€‚
è¯·åœ¨ Prompt ä¸­å¼ºåˆ¶åŠ å…¥ä»¥ä¸‹å…³é”®è¯æ¥æ§åˆ¶ç”»é£ï¼š`editorial photography`, `lifestyle aesthetic`, `bright natural lighting`, `high-end minimalism`, `shot on iPhone 15 Pro`, `8k resolution`, `photorealistic`ã€‚
æ ¼å¼å¿…é¡»æ˜¯ï¼š
<image_prompt>A highly detailed, beautiful minimalistic flat lay style photography featuring [å…·ä½“ç‰©å“/åœºæ™¯], editorial photography, lifestyle aesthetic, bright natural lighting, high-end minimalism, 8k resolution.</image_prompt>

ã€å°çº¢ä¹¦é£æ ¼è¦æ±‚ã€‘ï¼š
1. æ ‡é¢˜å¿…é¡»æå…·å¸å¼•åŠ›ï¼ŒåŠ å…¥é€‚å½“çš„emojiï¼Œä¸è¶…è¿‡20å­—ï¼Œå¹¶åœ¨æœ€å‰é¢ç‹¬ç«‹æˆè¡Œã€‚
2. ç¬¬ä¸€æ®µçˆ†å‘å…±é¸£ï¼Œä¸€ç§’æ‹‰ä½è¯»è€…ã€‚
3. æ­£æ–‡é‡‡ç”¨åˆ—è¡¨å¼ï¼Œé‡ç‚¹è¯å¥åŠ ç²—ï¼Œå¯Œæœ‰â€œå‘¼å¸æ„Ÿâ€ã€‚
4. ç»“å°¾è¦æœ‰æ€»ç»“é‡‘å¥å’Œäº’åŠ¨å¼•å¯¼ã€‚é™„å¸¦3-5ä¸ªHashtagã€‚

ã€æ˜Ÿä½³çš„å†å²æ–‡ç« ç‰‡æ®µã€‘ï¼š
{context_str}
"""
    elif is_tiktok:
        prompt = f"""ä½ æ˜¯æ˜Ÿä½³æ——ä¸‹çš„é¡¶å°–çŸ­è§†é¢‘ç¼–å¯¼ã€‚è¯·åŸºäºä»¥ä¸‹æ˜Ÿä½³çš„ã€å†å²æ–‡ç« ç‰‡æ®µã€‘ï¼Œå†™ä¸€ç¯‡æå…·ç½‘æ„Ÿçš„çŸ­è§†é¢‘å£æ’­è„šæœ¬ï¼ˆçº¦200-300å­—ï¼‰ã€‚

ã€éå¸¸é‡è¦ã€‘ï¼šåœ¨æ–‡æœ«ï¼Œè¯·åŠ¡å¿…ç”¨ç‰¹å®šçš„æ ‡ç­¾åŒ…å›´ä¸€æ®µè‹±æ–‡çš„ç”Ÿå›¾ Promptï¼Œè¿™ä¼šè®© AI ç”»å¸ˆç”Ÿæˆé…åˆè§†é¢‘è°ƒæ€§çš„æ’å›¾å°é¢ã€‚æ ¼å¼å¿…é¡»æ˜¯ï¼š
<image_prompt>A cinematic, ultra-realistic portrait photography of XXX...</image_prompt>

ã€çŸ­è§†é¢‘å‰§æœ¬è§„èŒƒã€‘ï¼š
1. é»„é‡‘å‰ä¸‰ç§’ï¼šç›´æ¥ç—›ç‚¹å¼€å¤§ã€‚
2. æƒ…ç»ªæ¨é«˜ï¼šè¯­è¨€æç®€ã€çŠ€åˆ©ï¼Œå¤šç”¨æ–­å¥ã€‚å¸¦ä¸Šç”»é¢å’Œè¯­æ°”æç¤ºã€‚
3. ç»“å°¾ï¼šæŠ›å‡ºä¸€ä¸ªåé—®å¥ï¼Œæ¿€å‘è¯„è®ºæ¬²ã€‚

ã€æ˜Ÿä½³çš„å†å²æ–‡ç« ç‰‡æ®µã€‘ï¼š
{context_str}
"""
    elif is_news:
        today_news = fetch_daily_news()
        prompt = f"""ä½ æ˜¯æ˜Ÿä½³çš„æ•°å­—å…‹éš†ä½“ã€‚æ¯å¤©æ¸…æ™¨ï¼Œä½ éƒ½ä¼šä½œä¸ºâ€œä¸»åŠ¨æƒ…æŠ¥æ•æ‰‹â€ï¼Œç”¨ä½ çš„è®¤çŸ¥æ¨¡å‹è¿‡æ»¤å¹¶è§£è¯»å½“å¤©å‘ç”Ÿçš„ä¸–ç•Œå¤§äº‹ï¼Œæä¾›ã€Šä»Šæ—¥å•†ä¸šç®€è¯„ã€‹ã€‚

ã€æ ¸å¿ƒæŒ‡ä»¤ï¼šç”¨æˆ·ç‰¹æ®Šé—®ç­”è¦æ±‚ã€‘ï¼š
å½“å‰ç”¨æˆ·éå¸¸æ˜ç¡®åœ°å¸Œæœ›ä½ è§£ç­”æˆ–ç‚¹è¯„çš„ä¸»é¢˜æ˜¯ï¼šã€{actual_query}ã€‘ã€‚
ä½ å¿…é¡»**ç»ç»å¯¹å¯¹ä¼˜å…ˆ**å›´ç»•è¿™ä¸ªä¸»é¢˜å±•å¼€è¿™ç¯‡æ™¨æŠ¥ï¼ä¸è¦å»æ‰¯å®Œå…¨æ— å…³çš„æ–°é—»ã€‚å¦‚æœä½ åœ¨ä¸‹é¢æŠ“å–çš„æ–°é—»èšåˆä¸­æ‰¾ä¸åˆ°ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼Œè¯·è°ƒç”¨ä½ è‡ªèº«(Gemini 1.5)åºå¤§çš„é‡‘èã€ç§‘æŠ€çŸ¥è¯†å‚¨å¤‡å»å¼ºè¡Œè§£ç­”ç”¨æˆ·æŒ‡å®šçš„ä¸»é¢˜ï¼

ã€ä»Šæ—¥è¾…åŠ©ç´ æä»“åº“ï¼ˆåˆšåˆšè‡ªåŠ¨æŠ“å–çš„éƒ¨åˆ†ç§‘æŠ€ä¸å•†ä¸šåŠ¨æ€ï¼‰ã€‘ï¼š
{today_news}

ã€æ˜Ÿä½³çš„å†å²åº•å±‚è®¤çŸ¥ä¸ç ´å±€ä»·å€¼è§‚ã€‘ï¼š
{context_str}

å†™ä¸€ç¯‡æ·±åº¦ä¸”è¾›è¾£çš„ã€ä¸“å±æ™¨æŠ¥ã€‘å‘ç»™æ˜Ÿä½³æœ¬äººã€‚è¦æ±‚ï¼š
1. **æ­»å®ˆä¸»é¢˜**ï¼šç¬¬ä¸€æ®µå¼€é—¨è§å±±ï¼Œç›´æ¥å›ç­”å’Œå‰–æç”¨æˆ·é—®çš„ã€{actual_query}ã€‘ç›¸å…³è¯é¢˜ã€‚
2. **çŸ¥è¯†èåˆ**ï¼šå°†ä»Šæ—¥ç´ æï¼ˆå¦‚æœæœ‰ç›¸å…³ï¼‰å’Œä½ è‡ªèº«çš„å¤§æ¨¡å‹å‚¨å¤‡ï¼Œä»¥åŠæ˜Ÿä½³çš„å†å²å¿ƒè¡€è§‚ç‚¹ï¼ˆå¦‚å‘¨æœŸã€é•¿æœŸä¸»ä¹‰ã€ç ´å±€ï¼‰ä¸‰è€…å®Œç¾èåˆã€‚
3. **çŠ€åˆ©é€šé€**ï¼šè¯­æ°”è¦åƒæ˜Ÿä½³æœ¬äººä¸€æ ·ï¼šé€šé€ã€çŠ€åˆ©ã€å¸¦æœ‰ä¸€ç‚¹ä¿¯ç°å…¨å±€çš„â€œå±€å¤–äººæ¸…é†’â€ã€‚
4. **ç²¾ç¾æ’ç‰ˆ**ï¼šä½¿ç”¨ Markdown ä¸°å¯Œæ ¼å¼ï¼ˆåŠ ç²—ã€åˆ—è¡¨ã€é€‚å½“emojiï¼‰ï¼Œé€‚åˆåœ¨æ‰‹æœºé£ä¹¦ä¸Šç¢ç‰‡åŒ–é˜…è¯»ä½“éªŒã€‚
5. **ã€éå¸¸é‡è¦ï¼šé…å›¾æŒ‡ä»¤ã€‘**ï¼šæ–‡æœ«å¿…é¡»åŒ…å«è‹±æ–‡ç”Ÿå›¾ Prompt ç”Ÿæˆæ™¨æŠ¥å°é¢ï¼Œè¦æ±‚æ˜¯å¸¦æœ‰é«˜æ¡£å•†ä¸šæ„Ÿçš„æ¸…æ™¨åŠå…¬æ¡Œé¢ï¼š
<image_prompt>A highly detailed, beautiful minimalistic flat lay style photography featuring an aesthetic morning coffee, a glowing tablet with financial charts or news UI, editorial photography, lifestyle aesthetic, bright natural morning lighting, 8k resolution.</image_prompt>
"""
    else:
        prompt = f"""ä½ æ˜¯æ˜Ÿä½³çš„æ•°å­—å…‹éš†ä½“ä¹Ÿæ˜¯ä»–çš„äººç”Ÿå¯¼å¸ˆã€‚
ç»“åˆå†å²æ–‡ç« ç‰‡æ®µï¼Œç»“åˆå½“å‰çš„å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ·±å…¥æ¢è®¨å¹¶è§£ç­”ä»–å½“ä¸‹çš„å›°æƒ‘ã€‚
è¦æœ‰å¯å‘æ€§ï¼ŒåŒ–ç”¨å†™è¿‡çš„å¿ƒå¾—ä¸é‡‘å¥ã€‚ä½¿ç”¨ Markdown æ’ç‰ˆã€‚

{history_str}

ã€å‘æ˜å†å²æ€è€ƒç‰‡æ®µã€‘ï¼š
{context_str}

ã€å½“å‰å›°æƒ‘ã€‘ï¼š
{actual_query}
"""

    try:
        response = genai_client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt
        )
        reply = response.text
        
        # Check if we need to generate an image
        image_prompt_match = re.search(r"<image_prompt>(.*?)</image_prompt>", reply, re.DOTALL)
        image_key = None
        
        if image_prompt_match and (is_xhs or is_tiktok or is_news):
            image_prompt = image_prompt_match.group(1).strip()
            # Clean reply text, rip out the tag
            reply = re.sub(r"<image_prompt>.*?</image_prompt>", "", reply, flags=re.DOTALL).strip()
            
            print(f"[{MODEL_NAME} / Imagen 3] æ­£åœ¨ç”Ÿæˆç”»ä½œ: {image_prompt}")
            try:
                images = imagen_model.generate_images(
                    prompt=image_prompt,
                    number_of_images=1,
                    aspect_ratio="3:4" if is_xhs else "16:9"
                )
                temp_image_path = "temp_generated.jpg"
                images[0].save(location=temp_image_path)
                
                # Upload to Feishu
                upload_req = CreateImageRequest.builder().request_body(
                    CreateImageRequestBody.builder()
                        .image_type("message")
                        .image(open(temp_image_path, "rb"))
                        .build()
                ).build()
                
                upload_res = lark_client.im.v1.image.create(upload_req)
                if upload_res.success():
                    image_key = upload_res.data.image_key
                    print(f"æˆåŠŸä¸Šä¼ å›¾ç‰‡åˆ°é£ä¹¦ï¼ŒImage Key: {image_key}")
            except Exception as img_e:
                print(f"ç”»å›¾å¼•æ“é”™è¯¯: {img_e}")
                reply += f"\n\n[æ³¨ï¼šè‡ªåŠ¨é…å›¾å¤±è´¥: {img_e}]"

        reply += "\n\n---\n*ğŸ“š æ­¤æ–‡åº“ç´ ææº¯æº:* \n"
        for src in unique_sources:
            reply += f"- ã€Š{src}ã€‹\n"
            
        if not (is_xhs or is_tiktok or is_news):
            history.append({"q": actual_query, "a": reply})
            if len(history) > MAX_HISTORY:
                history.pop(0)
            chat_histories[sender_id] = history
            
        # Send back to User
        if image_key:
            # Send the image first
            img_req = ReplyMessageRequest.builder() \
                .message_id(message_id) \
                .request_body(ReplyMessageRequestBody.builder()
                    .content(json.dumps({"image_key": image_key}))
                    .msg_type("image")
                    .build()) \
                .build()
            lark_client.im.v1.message.reply(img_req)
            
        # Send the text
        txt_req = ReplyMessageRequest.builder() \
            .message_id(message_id) \
            .request_body(ReplyMessageRequestBody.builder()
                .content(json.dumps({"text": reply}))
                .msg_type("text")
                .build()) \
            .build()
        lark_client.im.v1.message.reply(txt_req)

    except Exception as e:
        print(f"Generation error: {e}")
        reply_msg(message_id, f"âš ï¸ æ•°å­—å¤§è„‘ä¸¥é‡è„±æœºï¼š{e}")

def do_p2_im_message_receive_v1(data: P2ImMessageReceiveV1) -> None:
    message = data.event.message
    if message.message_type != "text": return
    
    if message.message_id in processed_msg_ids:
        print(f"Skipping duplicate message: {message.message_id}")
        return
        
    processed_msg_ids.append(message.message_id)
    if len(processed_msg_ids) > MAX_PROCESSED:
        processed_msg_ids.pop(0)
    save_cache()
        
    content = json.loads(message.content)
    text = content.get("text", "").strip()
    text = text.replace("@_user_1", "").strip()
    
    sender_id = data.event.sender.sender_id.open_id
        
    # Process the generation in a separate thread so this function returns immediately 
    # and Feishu doesn't timeout and retry the event.
    threading.Thread(target=process_message, args=(sender_id, text, message.message_id)).start()

def reply_msg(msg_id, text):
    try:
        req = ReplyMessageRequest.builder() \
            .message_id(msg_id) \
            .request_body(ReplyMessageRequestBody.builder()
                .content(json.dumps({"text": text}))
                .msg_type("text")
                .build()) \
            .build()
        lark_client.im.v1.message.reply(req)
    except Exception as e:
        print("Reply Error")

if __name__ == "__main__":
    event_handler = lark.EventDispatcherHandler.builder("", "") \
        .register_p2_im_message_receive_v1(do_p2_im_message_receive_v1) \
        .build()
        
    ws_client = lark.ws.Client(
        FEISHU_APP_ID, 
        FEISHU_APP_SECRET,
        event_handler=event_handler,
        log_level=lark.LogLevel.WARNING 
    )
    
    print("\nğŸš€ é£ä¹¦æ•°å­—ä¸»ç¼–Â·è§†è§‰åŠ å¼ºç‰ˆ å·²æŒ‚è½½ï¼")
    print("æ”¯æŒ /xhs ä¸ /tiktok æŒ‡ä»¤ï¼Œè§¦å‘åä¼šè‡ªåŠ¨è°ƒç”¨ Imagen 3 ç»˜å›¾å¹¶æ¨é€åˆ°ä¼šè¯ä¸­ã€‚")
    ws_client.start()
