import os
import re
import subprocess
import random
import streamlit as st
from dotenv import load_dotenv
from google import genai
from langchain_google_vertexai import VertexAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.documents import Document

load_dotenv()

# --- Configuration ---
PROJECT_ID = os.environ.get("GCP_PROJECT_ID", "gen-lang-client-0834352502")
LOCATION = os.environ.get("GCP_LOCATION", "us-central1")

# Automatically use relative path
CHROMA_PERSIST_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "chroma_db")

EMBEDDING_MODEL = "text-embedding-004"
API_KEY = os.environ.get("GOOGLE_API_KEY", "")
MAX_HISTORY = 3
TEMP_AUDIO_FILE = "web_voice.mp3"

# --- UI Configuration Setup ---
st.set_page_config(
    page_title="æ˜Ÿä½³çš„æ•°å­—ç”Ÿæ€",
    page_icon="ğŸŒŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Initialize Clients ---
@st.cache_resource
def get_clients():
    client = genai.Client(api_key=API_KEY)
    
    available = []
    for m in client.models.list():
        if 'gemini' in m.name.lower() and 'generate' in str(getattr(m, 'supported_actions', '')).lower():
            available.append(m.name)
            
    chosen_model = "gemini-2.0-flash" 
    for preferred in ["gemini-2.5-pro", "gemini-2.0-flash", "gemini-1.5-pro"]:
        for a in available:
            if preferred in a:
                chosen_model = a
                break
        if chosen_model != "gemini-2.0-flash":
            break
            
    # --- æœ€ç»ˆä¿®å¤ï¼šVM çš„ access scopes å·²ä¿®æ­£ä¸º cloud-platformï¼Œæ¢å¤ä½¿ç”¨åŸç”Ÿçš„ Vertex AI Embeddings ---
    from langchain_google_vertexai import VertexAIEmbeddings
    embeddings = VertexAIEmbeddings(model_name=EMBEDDING_MODEL, project=PROJECT_ID, location=LOCATION)

    vectorstore = Chroma(persist_directory=CHROMA_PERSIST_DIR, embedding_function=embeddings, collection_name="wechat_articles")
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    
    return client, chosen_model, retriever, vectorstore

# --- Helper Functions ---
def format_docs(docs, for_writer=False):
    formatted = []
    for d in docs:
        source = d.metadata.get('source_file', 'æœªçŸ¥æ–‡ç« ')
        label = "å‚è€ƒç¯‡ç›®" if for_writer else "æ‘˜è‡ªæ–‡ç« "
        formatted.append(f"ã€{label}ï¼šã€Š{source}ã€‹ã€‘\n{d.page_content}")
    return "\n\n---\n\n".join(formatted)

def clean_for_tts(text):
    text = re.sub(r'[*_#`]', '', text)
    text = re.sub(r'\[.*?\]\(.*?\)', '', text) 
    text = text.replace('\n', 'ã€‚')
    # Clean up sources
    text = re.split(r'\(\s*ğŸ’¡ \*\*å¼•ç”¨çš„å†å²çµæ„Ÿ\*\*', text)[0]
    return text[:800] 

def generate_audio(text):
    clean_txt = clean_for_tts(text)
    cmd = f'edge-tts --text "{clean_txt}" --voice zh-CN-YunxiNeural --write-media {TEMP_AUDIO_FILE}'
    try:
        subprocess.run(cmd, shell=True, check=True)
        return True
    except Exception as e:
        print(f"TTS Error: {e}")
        return False

# --- App Logic ---
def check_password():
    """Returns `True` if the user had the correct password."""
    def password_entered():
        expected_password = os.environ.get("APP_PASSWORD", "xingjia2026")
        if st.session_state["password"] == expected_password: 
            st.session_state["password_correct"] = True
            del st.session_state["password"]  # don't store password
        else:
            st.session_state["password_correct"] = False

    if "password_correct" not in st.session_state:
        st.text_input(
            "ğŸ”’ è¯·è¾“å…¥ä¸“å±é¡¾é—®å’¨è¯¢è®¿é—®å£ä»¤", type="password", on_change=password_entered, key="password"
        )
        return False
    elif not st.session_state["password_correct"]:
        st.text_input(
            "ğŸ”’ è¯·è¾“å…¥ä¸“å±é¡¾é—®å’¨è¯¢è®¿é—®å£ä»¤", type="password", on_change=password_entered, key="password"
        )
        st.error("ğŸ”‘ å£ä»¤ä¸æ­£ç¡®ï¼Œè¯·é‡æ–°è¾“å…¥æˆ–è”ç³»æ˜Ÿä½³è·å–ã€‚")
        return False
    else:
        return True

def main():
    if not check_password():
        st.stop()
        
    if not os.path.exists(CHROMA_PERSIST_DIR):
        st.error(f"âŒ æ‰¾ä¸åˆ°æœ¬åœ°çŸ¥è¯†åº“ç›®å½•ï¼š{CHROMA_PERSIST_DIR}ã€‚è¯·å…ˆè¿è¡Œ `rag_ingest.py`ã€‚")
        st.stop()
        
    try:
        client, chosen_model, retriever, vectorstore = get_clients()
    except Exception as e:
        st.error(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        st.stop()

    # Navigation
    st.sidebar.title("ğŸŒŒ æ˜Ÿä½³çš„æ•°å­—ç”Ÿæ€")
    app_mode = st.sidebar.radio("é€‰æ‹©åŠŸèƒ½æ¨¡å—", ["ğŸ§  çµé­‚å¯¼å¸ˆ (å¯¹è¯)", "âœï¸ æ›¿èº«å†™ä½œ (AI Writer)", "ğŸ¤” æ€æƒ³å›¾è°± (Knowledge Graph)", "ğŸ¦ æ¨ç‰¹åˆ†å‘æœº (Twitter Agent)"])
    
    st.sidebar.markdown("---")
    st.sidebar.info(f"**æ¨¡å‹**: `{chosen_model}`\n\n**çŸ¥è¯†åº“**: 1.8ä¸‡+ åˆ‡ç‰‡")

    if app_mode == "ğŸ§  çµé­‚å¯¼å¸ˆ (å¯¹è¯)":
        render_chat_mentor(client, chosen_model, vectorstore)
    elif app_mode == "âœï¸ æ›¿èº«å†™ä½œ (AI Writer)":
        render_ai_writer(client, chosen_model, vectorstore)
    elif app_mode == "ğŸ¤” æ€æƒ³å›¾è°± (Knowledge Graph)":
        render_knowledge_graph(client, chosen_model, vectorstore)
    elif app_mode == "ğŸ¦ æ¨ç‰¹åˆ†å‘æœº (Twitter Agent)":
        render_twitter_agent(client, chosen_model, vectorstore)

# --- Feature 1: Chat Mentor ---
def render_chat_mentor(client, chosen_model, vectorstore):
    st.title("ğŸ§  æ˜Ÿä½³çš„æ•°å­—å¯¼å¸ˆ")
    st.markdown("æ±‡èšäº”å¹´æ€è€ƒç»“æ™¶ï¼Œå¯ä»¥åœ¨ä¾§è¾¹æ å¼€å¯è¯­éŸ³æ’­æŠ¥ã€‚")
    
    enable_voice = st.sidebar.checkbox("ğŸ”Š å¼€å¯è¯­éŸ³æ’­æŠ¥ (TTS)", value=False)
    if st.sidebar.button("ğŸ§¹ æ¸…ç©ºå¯¹è¯è®°å¿†", use_container_width=True):
        st.session_state.messages = []
        st.session_state.chat_history = []
        st.rerun()

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼Œæ˜Ÿä½³ã€‚æˆ‘æ˜¯ä½ çš„æ•°å­—åˆ†èº«ä¸è€æœ‹å‹ã€‚æœ€è¿‘æœ‰ä»€ä¹ˆå›°æƒ‘ï¼Œè¯´æ¥å¬å¬ï¼Ÿ", "audio": None}]
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if message.get("audio") and os.path.exists(message["audio"]):
                st.audio(message["audio"])

    if prompt := st.chat_input("æœ‰ä»€ä¹ˆå›°æƒ‘ï¼Ÿè¯´æ¥å¬å¬..."):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            audio_placeholder = st.empty()
            
            with st.spinner('å¯¼å¸ˆæ²‰æ€ä¸­...'):
                search_query = prompt
                if st.session_state.chat_history:
                    search_query = f"å…³äº {st.session_state.chat_history[-1]['q']} çš„æ¢è®¨: {prompt}"
                
                docs = vectorstore.similarity_search(search_query, k=5) 
                context_str = format_docs(docs)
                
                unique_sources = list(set([d.metadata.get('source_file', 'æœªçŸ¥') for d in docs]))
                
                history_str = ""
                if st.session_state.chat_history:
                    history_str = "\nã€æœ€è¿‘çš„å¯¹è¯å†å²ã€‘ï¼š\n"
                    for h in st.session_state.chat_history:
                        history_str += f"æ˜Ÿä½³: {h['q']}\nå¯¼å¸ˆ: {h['a'][:150]}...\n"
                        
                voice_rule = "ä½ çš„å›ç­”å¿…é¡»éå¸¸å£è¯­åŒ–ï¼Œåƒè€æœ‹å‹åœ¨é¢å¯¹é¢èŠå¤©ï¼ˆä¸è¦ç”¨åˆ—æ¡ç›®ï¼‰ï¼Œå­—æ•°ç²¾ç®€ï¼Œä»¥ä¾¿è½¬åŒ–ä¸ºè¯­éŸ³ã€‚" if enable_voice else "ä½ çš„æ’ç‰ˆè¦ç¾è§‚æ¸…æ™°ï¼Œé€‚åˆé˜…è¯»ã€‚"
                
                sys_prompt = f"""ä½ æ˜¯æ˜Ÿä½³çš„æ•°å­—å…‹éš†ä½“ä¹Ÿæ˜¯ä»–çš„äººç”Ÿå¯¼å¸ˆã€‚
è¯·ç»“åˆå†å²æ–‡ç« ç‰‡æ®µå’Œå¯¹è¯ä¸Šä¸‹æ–‡ï¼Œæ·±å…¥æ¢è®¨å¹¶è§£ç­”ä»–å½“ä¸‹çš„å›°æƒ‘ã€‚

ã€è¦æ±‚ã€‘ï¼š
1. å…·æœ‰å¯å‘æ€§ï¼Œåƒæ·±äº¤å¤šå¹´çš„æŒšå‹åœ¨å¯å‘ä»–æ€è€ƒã€‚
2. æ½œç§»é»˜åŒ–åœ°åŒ–ç”¨ä»–è¿‡å»å†™è¿‡çš„å¿ƒå¾—ä¸é‡‘å¥ã€‚
3. {voice_rule}

{history_str}

ã€å†å²ç‰‡æ®µã€‘ï¼š
{context_str}

ã€å½“å‰çš„å›°æƒ‘ã€‘ï¼š
{prompt}

ä½ çš„å›ç­”ï¼š"""

            full_response = ""
            try:
                for chunk in client.models.generate_content_stream(model=chosen_model, contents=sys_prompt):
                    if chunk.text:
                        full_response += chunk.text
                        message_placeholder.markdown(full_response + "â–Œ")
                
                source_text = "\n\n*(ğŸ’¡ **å¼•ç”¨çš„å†å²çµæ„Ÿ**:*\n"
                for src in unique_sources:
                    source_text += f"*- ã€Š{src}ã€‹*\n"
                source_text += ")"
                
                full_response += source_text
                message_placeholder.markdown(full_response)
                
                audio_path = None
                if enable_voice:
                    with st.spinner("æ­£åœ¨ç”Ÿæˆè¯­éŸ³..."):
                        if generate_audio(full_response):
                            audio_path = TEMP_AUDIO_FILE
                            audio_placeholder.audio(audio_path)
                
            except Exception as e:
                full_response = f"æŠ±æ­‰ï¼Œé‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼š{e}"
                message_placeholder.markdown(full_response)

        st.session_state.messages.append({"role": "assistant", "content": full_response, "audio": audio_path})
        st.session_state.chat_history.append({"q": prompt, "a": full_response})
        if len(st.session_state.chat_history) > MAX_HISTORY:
            st.session_state.chat_history.pop(0)

# --- Feature 2: AI Writer ---
def render_ai_writer(client, chosen_model, vectorstore):
    st.title("âœï¸ æ›¿èº«å†™ä½œ (AI Writer)")
    st.markdown("è¾“å…¥çµæ„Ÿæˆ–ä¸»é¢˜ï¼Œç³»ç»Ÿå°†æ£€ç´¢ä½ çš„ 1.8 ä¸‡ä¸ªå†å²åˆ‡ç‰‡ï¼Œå®Œå…¨æ¨¡ä»¿ä½ çš„ç¬”è§¦è‡ªåŠ¨æ‹¼è£…å‡ºå›¾æ–‡å¹¶èŒ‚çš„å…¬ä¼—å·åˆç¨¿ã€‚")
    
    topic = st.text_area("æ–‡ç« ä¸»é¢˜æˆ–çµæ„Ÿå…³é”®è¯", placeholder="ä¾‹å¦‚ï¼šä¸ºä»€ä¹ˆæ™®é€šäººå¾ˆéš¾çœŸæ­£åšåˆ°é•¿æœŸä¸»ä¹‰ï¼Ÿ", height=100)
    
    if st.button("ğŸš€ ç”Ÿæˆæ–‡ç« åˆç¨¿", type="primary"):
        if not topic.strip():
            st.warning("è¯·è¾“å…¥æ–‡ç« ä¸»é¢˜ï¼")
            return
            
        st.markdown("---")
        result_placeholder = st.empty()
        full_article = ""
        
        with st.spinner("æ­£åœ¨ä» 1.8ä¸‡ ä¸ªå†å²ç‰‡æ®µä¸­æ£€ç´¢ç›¸å…³çµæ„Ÿ..."):
            retriever = vectorstore.as_retriever(search_kwargs={"k": 8})
            docs = retriever.invoke(topic)
            context_str = format_docs(docs, for_writer=True)
            
            unique_sources = list(set([d.metadata.get('source_file', 'æœªçŸ¥') for d in docs]))
            st.success(f"æ‰¾åˆ°äº† {len(unique_sources)} ç¯‡ç›¸å…³å†å²æ–‡ç« ä½œä¸ºé£æ ¼å‚è€ƒï¼")
            with st.expander("æŸ¥çœ‹å‚è€ƒçš„å‡ºå¤„"):
                for src in unique_sources:
                    st.write(f"- {src}")
                    
        with st.spinner("æ­£åœ¨æç¬”æ’°å†™ï¼Œæ¨¡ä»¿æ˜Ÿä½³çš„æ–‡é£..."):
            prompt = f"""ä½ æ˜¯æ˜Ÿä½³ï¼Œä¸€ä½æ·±è€•äº’è”ç½‘ã€æ•™è‚²è§„åˆ’ã€è‡ªæˆ‘æˆé•¿çš„å…¬ä¼—å·ä¸»ç†äººã€‚
ç°åœ¨ä½ éœ€è¦å†™ä¸€ç¯‡æ–°çš„å¾®ä¿¡å…¬ä¼—å·æ–‡ç« åˆç¨¿ï¼Œä¸»é¢˜æ˜¯ï¼šã€{topic}ã€‘ã€‚

è¯·ä½ å…ˆé˜…è¯»ä»¥ä¸‹ä½ è¿‡å»å†™è¿‡çš„ç›¸å…³æ–‡ç« ç‰‡æ®µï¼Œä»”ç»†ä½“ä¼šä½ è‡ªå·±çš„å†™ä½œæ–‡é£ã€æ’ç‰ˆä¹ æƒ¯ã€å¸¸ç”¨é‡‘å¥å’Œæ€ç»´é€»è¾‘ï¼š

ã€å†å²é£æ ¼å‚è€ƒã€‘ï¼š
{context_str}

ã€å†™ä½œè¦æ±‚ã€‘ï¼š
1. ä½ çš„æ–‡ç« å¸¦æœ‰å¼ºçƒˆçš„ä¸ªäººç»éªŒè‰²å½©å’Œæ•…äº‹æ€§ï¼Œåƒæ˜¯åœ¨è·Ÿè¯»è€…äº¤å¿ƒã€‚
2. å®Œç¾å¤åˆ»å†å²å‚è€ƒç‰‡æ®µä¸­çš„å†™ä½œé£æ ¼ï¼ŒåŒ…æ‹¬è‡ªç„¶çš„åˆ†æ®µã€åˆç†çš„è®¾é—®ã€ä»¥åŠä¸€é’ˆè§è¡€çš„æ–­è¨€ã€‚
3. è¯·ä¸ºè¿™ç¯‡æ–‡ç« èµ·ä¸€ä¸ªå¸¦æœ‰ç‚¹â€œæ˜Ÿä½³å‘³é“â€çš„æ ‡é¢˜ï¼ˆæ”¾åœ¨å…¨æ–‡æœ€å‰é¢ï¼‰ã€‚
4. å­—æ•°è¦æ±‚åœ¨ 1500 å­—å·¦å³ï¼Œç»“æ„ä¸Šè¦æœ‰ï¼šå¼•å…¥ -> ç ´é¢˜ -> è®ºè¯ -> ç»“è®ºã€‚
5. ç›´æ¥è¾“å‡º Markdown æ ¼å¼çš„æ­£å¼æ–‡ç« å†…å®¹ï¼Œä¸éœ€è¦åºŸè¯ã€‚

å¼€å§‹åˆ›ä½œå§ï¼š"""

            try:
                for chunk in client.models.generate_content_stream(model=chosen_model, contents=prompt):
                    if chunk.text:
                        full_article += chunk.text
                        result_placeholder.markdown(full_article + " â–Œ")
                result_placeholder.markdown(full_article)
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

# --- Feature 3: Knowledge Graph ---
def render_knowledge_graph(client, chosen_model, vectorstore):
    st.title("ğŸ¤” ä¸ªäººæ€æƒ³å›¾è°±")
    st.markdown("è®© AI ä»ä½ çš„å†å²æ–‡ç« åº“ä¸­éšæœºæŠ½å–å¤§é‡æ•°æ®ï¼Œæç‚¼å¹¶å¯è§†åŒ–ä½ çš„æ ¸å¿ƒç†å¿µç½‘ç»œã€‚")
    
    if st.button("ğŸ§¬ å¼€å§‹æ·±åº¦æŒ–æ˜å¹¶ç”Ÿæˆå›¾è°±"):
        st.markdown("---")
        
        with st.spinner("æ­£åœ¨è¯»å–çŸ¥è¯†åº“æ•°æ®..."):
            collection_data = vectorstore._collection.get()
            all_docs = collection_data['documents']
            total_docs = len(all_docs)
            sample_size = min(200, total_docs)
            
            sampled_docs = random.sample(all_docs, sample_size)
            combined_text = "\n\n".join(sampled_docs)
            st.info(f"å·²ä» {total_docs} ä¸ªç‰‡æ®µä¸­éšæœºæŠ½æ ·äº† {sample_size} ä¸ªæ ¸å¿ƒç‰‡æ®µã€‚")
            
        with st.spinner("æ­£åœ¨ç”¨å¤§æ¨¡å‹è¿›è¡Œä¸»é¢˜æç‚¼ä¸å…³ç³»æ¨æ¼”..."):
            prompt = f"""è¯·åˆ†æä»¥ä¸‹è¿™ {sample_size} ä¸ªæ–‡å­—ç‰‡æ®µï¼ˆè¿™åªæ˜¯ä½œè€…è¿‡å»äº”å¹´æ–‡ç« çš„éšæœºæŠ½æ ·ï¼‰ã€‚

ä½ çš„ä»»åŠ¡æ˜¯æå–å‡ºä»£è¡¨ä½œè€…æœ€æ ¸å¿ƒç†å¿µã€æ€è€ƒæ¨¡å‹ã€å…³æ³¨é¢†åŸŸçš„ **30 ä¸ª**å…³é”®è¯æˆ–çŸ­è¯­ï¼Œå¹¶æ„å»ºä¸€ä¸ªé«˜åº¦å…³è”çš„çŸ¥è¯†å›¾è°±ã€‚

è¦æ±‚ï¼š
1. **ç»“æ„åŒ–**ï¼šä½¿ç”¨ Mermaid `graph LR` (ä»å·¦åˆ°å³) å¸ƒå±€ï¼Œè¿™æ ·åœ¨ç¤¾äº¤åª’ä½“é•¿å›¾ä¸Šæ›´å¥½çœ‹ã€‚
2. **ç¾åŒ–**ï¼šåˆ©ç”¨ `subgraph` å°†ç›¸å…³çš„è¯æ±‡è¿›è¡Œèšç±»ï¼ˆä¾‹å¦‚ï¼šå®¶åº­ä¸èµ„äº§ã€ä¸ªäººæˆé•¿ã€AIä¸å·¥å…·ï¼‰ã€‚
3. **èŠ‚ç‚¹åˆ†çº§**ï¼šæœ€é‡è¦çš„ 3-5 ä¸ªæ ¸å¿ƒè¯æ±‡è¯·ä½¿ç”¨ `èŠ‚ç‚¹ID((æ–‡å­—))` è¿™ç§åŒåœˆè¡¨ç¤ºã€‚
4. **ç®€æ´**ï¼šåªè¾“å‡º Mermaid ä»£ç ï¼Œç”¨ ```mermaid å‰åç¼€åŒ…è£¹ã€‚ç»å¯¹ä¸è¦åœ¨æ–‡å­—ä¸­å‡ºç°å†’å·ã€æ‹¬å·ã€ä¸­æ‹¬å·ç­‰ç‰¹æ®Šå­—ç¬¦ï¼Œé™¤éä½ ç”¨åŒå¼•å·åŒ…è£¹å®ƒä»¬ã€‚
5. **ç¤¾äº¤å±æ€§**ï¼šè¿æ¥çº¿å°½é‡å¸¦ä¸Šè¯´æ˜ï¼ˆæ¯”å¦‚ï¼šA -- ä¿ƒè¿› --> Bï¼‰ã€‚
6. **æ— æŸè¾“å‡º**ï¼šç¡®ä¿èŠ‚ç‚¹ ID å”¯ä¸€ï¼Œä¸è¦å‡ºç°é‡å¤çš„èŠ‚ç‚¹å®šä¹‰ã€‚

ã€æŠ½æ ·ææ–™ã€‘ï¼š
{combined_text[:60000]}

Mermaid å›¾è¡¨ä»£ç ï¼š"""

            full_response = ""
            graph_placeholder = st.empty()
            try:
                for chunk in client.models.generate_content_stream(model=chosen_model, contents=prompt):
                    if chunk.text:
                        full_response += chunk.text
                        graph_placeholder.markdown(full_response)
                
                match = re.search(r'```mermaid(.*?)```', full_response, re.DOTALL)
                if match:
                    mermaid_code = match.group(1).strip()
                    
                    # --- Defensive Cleaning: Fix common Mermaid syntax errors ---
                    # 1. Fix unbalanced parentheses inside nodes (common LLM error like P((text)))
                    # This regex finds patterns like ((text)) or (text) and ensures the content is safely quoted
                    # Specifically fix the user's error: K3("(åšå‡ºç»“æœ")) -> K3("åšå‡ºç»“æœ")
                    mermaid_code = re.sub(r'(\w+)\s*\(\s*["\']?\s*\((.*?)\)\s*["\']?\s*\)', r'\1("\2")', mermaid_code)
                    
                    # 2. General Quoting for nodes with special characters
                    mermaid_code = re.sub(r'([\[\(])([^"\]\)]*?[:\(\)\[\]/][^"\]\)]*?)([\]\)])', r'\1"\2"\3', mermaid_code)
                    
                    # 3. Clean up any double-double quotes caused by multiple regex passes
                    mermaid_code = mermaid_code.replace('""', '"')
                    
                    # 4. Remove characters that break Mermaid even inside quotes
                    mermaid_code = mermaid_code.replace('$', 'USD').replace('&', ' and ')
                    
                    graph_placeholder.empty()
                    # è°ƒè¯•ç”¨ï¼šæ˜¾ç¤ºä»£ç 
                    with st.expander("ğŸ› ï¸ æŸ¥çœ‹å›¾è°±æºä»£ç  (è°ƒè¯•ç”¨)"):
                        st.code(mermaid_code, language="mermaid")
                    
                    # æ³¨å…¥ç²¾ç¾æ ·å¼
                    st.components.v1.html(
                        f'''
                        <style>
                            .container {{
                                background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
                                border-radius: 20px;
                                padding: 30px;
                                border: 1px solid rgba(255,255,255,0.1);
                                box-shadow: 0 25px 50px -12px rgba(0,0,0,0.5);
                                font-family: "Inter", sans-serif;
                                overflow: auto;
                            }}
                            .header {{
                                color: #38bdf8;
                                font-size: 14px;
                                letter-spacing: 2px;
                                text-transform: uppercase;
                                margin-bottom: 20px;
                                text-align: center;
                                font-weight: 600;
                            }}
                            .footer {{
                                margin-top: 20px;
                                text-align: right;
                                color: rgba(255,255,255,0.4);
                                font-size: 12px;
                            }}
                            .mermaid {{
                                display: flex;
                                justify-content: center;
                            }}
                            /* Mermaid Node Styling Override */
                            .node rect, .node circle, .node polygon, .node path {{
                                fill: rgba(56, 189, 248, 0.1) !important;
                                stroke: #38bdf8 !important;
                                stroke-width: 1.5px !important;
                            }}
                            .node .label {{
                                color: #e2e8f0 !important;
                                font-weight: 500 !important;
                            }}
                            .edgePath .path {{
                                stroke: rgba(255, 255, 255, 0.2) !important;
                                stroke-width: 1px !important;
                            }}
                            .edgeLabel {{
                                background-color: transparent !important;
                                color: #94a3b8 !important;
                                font-size: 10px !important;
                            }}
                        </style>
                        <div class="container">
                            <div class="header">ğŸŒŒ æ˜Ÿä½³æ€æƒ³æ¼”åŒ–å›¾è°± Â· 2026 </div>
                            <div class="mermaid">
                                {mermaid_code}
                            </div>
                            <div class="footer">ç”± æ˜Ÿä½³æ•°å­—ç”Ÿæ€ Â· æ•°å­—çµé­‚å¯¼å¸ˆ é©±åŠ¨ç”Ÿæˆ</div>
                        </div>
                        <script type="module">
                            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
                            mermaid.initialize({{ 
                                startOnLoad: true, 
                                theme: 'dark',
                                themeVariables: {{
                                    primaryColor: '#38bdf8',
                                    primaryTextColor: '#fff',
                                    primaryBorderColor: '#38bdf8',
                                    lineColor: '#576574',
                                    secondaryColor: '#0061ff',
                                    tertiaryColor: '#fff',
                                    fontSize: '14px'
                                }}
                            }});
                        </script>
                        ''',
                        height=800,
                        scrolling=True
                    )
                    st.success("å›¾è°±æ¸²æŸ“å®Œæˆï¼ç°åœ¨çš„è§†è§‰æ•ˆæœéå¸¸é€‚åˆæˆªå›¾å‘é€è‡³ç¤¾äº¤å¹³å°ã€‚")
                else:
                    st.warning("æœªèƒ½æå–åˆ°å›¾è°±ä»£ç ã€‚")
            except Exception as e:
                st.error(f"æå–å¤±è´¥ï¼š{e}")

# --- Feature 4: Twitter Agent ---
def render_twitter_agent(client, chosen_model, vectorstore):
    st.title("ğŸ¦ æ¨ç‰¹åˆ†å‘æœº (Twitter Agent)")
    st.markdown("åŠè‡ªåŠ¨é˜²å°ç‰ˆï¼šç³»ç»Ÿå°†ä»ä½ çš„æµ·é‡å…¬ä¼—å·å†å²ä¸­æå–çµå…‰ä¸€é—ªçš„å•†ä¸š/äººç”Ÿæ´å¯Ÿï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºé€‚åˆåœ¨ X (Twitter) ä¸Šå‘å¸ƒçš„é«˜è´¨é‡åŒè¯­æ¨æ–‡ï¼Œç”šè‡³é™„å¸¦é…å›¾æç¤ºè¯ã€‚")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        topic = st.text_input("æƒ³èŠç‚¹ä»€ä¹ˆæ–¹å‘ï¼Ÿï¼ˆç•™ç©ºåˆ™å®Œå…¨éšæœºç¢°æ’ï¼‰", placeholder="ä¾‹å¦‚ï¼šè®¤çŸ¥ç ´å±€ã€æŠ•èµ„ã€æˆ–è€…æ˜¯æ—¶é—´ç®¡ç†...")
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        generate_btn = st.button("âœ¨ æç‚¼ç”Ÿæˆçˆ†æ¬¾æ¨æ–‡", type="primary", use_container_width=True)
        
    if generate_btn:
        st.markdown("---")
        result_placeholder = st.empty()
        full_tweet = ""
        
        with st.spinner("æ­£åœ¨è¿›å…¥ 1.8 ä¸‡ä¸ªè®°å¿†åˆ‡ç‰‡ä¸­æ‰“æçµæ„Ÿ..."):
            if topic.strip():
                retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
                docs = retriever.invoke(topic)
                context_str = format_docs(docs)
                sources = list(set([d.metadata.get('source_file', 'æœªçŸ¥') for d in docs]))
            else:
                collection_data = vectorstore._collection.get()
                all_docs = collection_data['documents']
                all_metadatas = collection_data['metadatas']
                sample_indices = random.sample(range(len(all_docs)), 5)
                
                docs = []
                for idx in sample_indices:
                    docs.append(Document(page_content=all_docs[idx], metadata=all_metadatas[idx]))
                
                context_str = format_docs(docs)
                sources = list(set([d.metadata.get('source_file', 'æœªçŸ¥') for d in docs]))

        with st.spinner("æ­£åœ¨ç”¨æä¸ºçŠ€åˆ©çš„æ–‡å­—é‡å¡‘æ¨ç‰¹å†…å®¹..."):
            topic_instruction = f"å½“å‰ç”¨æˆ·éå¸¸æ˜ç¡®åœ°å¸Œæœ›ä½ æ¢è®¨çš„ä¸»é¢˜æ˜¯ï¼šã€{topic}ã€‘ã€‚ä½ å¿…é¡»ç»å¯¹ä¼˜å…ˆå›´ç»•è¿™ä¸ªä¸»é¢˜å±•å¼€æ¨æ–‡ï¼å¦‚æœä½ æä¾›çš„å†å²ç¢ç‰‡ä¸­æ²¡æœ‰ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼Œè¯·ç»“åˆä½ è‡ªèº«çš„å•†ä¸šè®¤çŸ¥å¼ºè¡Œåˆ‡å…¥åˆ°è¯¥ä¸»é¢˜ï¼\n" if topic.strip() else ""
            
            prompt = f"""ä½ æ˜¯æ˜Ÿä½³ï¼Œä¸€ä½åœ¨ X (Twitter) ä¸Šæ‹¥æœ‰é«˜å½±å“åŠ›çš„åè¯­å•†ä¸šä¸ä¸ªäººæˆé•¿åšä¸»ã€‚
è¯·ç»“åˆä»¥ä¸‹ä»ä½ è¿‡å»å…¬ä¼—å·æ–‡ç« ä¸­æå–çš„ã€æ€æƒ³åˆ‡ç‰‡ã€‘ï¼Œå†™ä¸€æ¡èƒ½åœ¨æ¨ç‰¹ä¸Šå¼•å‘å¹¿æ³›å…±é¸£å’Œè½¬å‘çš„é«˜è´¨é‡æ¨æ–‡ï¼ˆTweetï¼‰ã€‚

{topic_instruction}
ã€æ€æƒ³åˆ‡ç‰‡æ¥æºã€‘ï¼š
{context_str}

ã€æ¨æ–‡å†™ä½œè§„èŒƒã€‘ï¼š
1. è¯­è¨€ï¼šè¾“å‡ºã€ä¸­æ–‡ç‰ˆã€‘å’Œåœ°é“çš„ã€è‹±æ–‡ç‰ˆã€‘åŒè¯­å¯¹ç…§ã€‚
2. é£æ ¼ï¼šçŠ€åˆ©ã€é€šé€ã€åç›´è§‰ã€‚å¸¦æœ‰â€œç¡…è°·å¤§ä½¬â€èˆ¬çš„æç®€æå®¢èŒƒã€‚
3. æ ¼å¼ï¼šç¬¬ä¸€å¥è¯å¿…é¡»æå…¶å¸ç›ï¼ˆHookï¼‰ã€‚æ­£æ–‡åˆ‡åˆ†çŸ­å¥ï¼Œå¤šç”¨ç©ºè¡Œã€‚å­—æ•°æ§åˆ¶åœ¨èƒ½ä¸€æ¬¡å‘å®Œçš„é•¿åº¦ï¼ˆä¸­æ–‡ 140 å­—ä»¥å†…ï¼‰ã€‚
4. æ ‡ç­¾ï¼šåœ¨æ¨æ–‡æœ«å°¾åŠ ä¸Š 2-3 ä¸ªåˆé€‚çš„è‹±æ–‡ Hashtagï¼ˆå¦‚ #Mindset #Crypto ç­‰ï¼‰ã€‚
5. é…å›¾æŒ‡ä»¤ï¼šåœ¨æœ€åº•ä¸‹ï¼Œé™„å¸¦æä¾›ä¸€æ®µå®Œç¾çš„è‹±æ–‡ AI ç»˜ç”» Promptï¼Œæè¿°ä¸€å¼ é€‚åˆè¿™æ¡æ¨æ–‡çš„æç®€é«˜çº§æ„Ÿé…å›¾ï¼ˆä¾‹å¦‚ï¼šA cinematic high-end photography of ...ï¼‰ã€‚

ç›´æ¥è¾“å‡ºæ’ç‰ˆå¥½çš„æ¨æ–‡ç»“æœï¼š"""

            try:
                for chunk in client.models.generate_content_stream(model=chosen_model, contents=prompt):
                    if chunk.text:
                        full_tweet += chunk.text
                        result_placeholder.markdown(full_tweet + " â–Œ")
                
                full_tweet += "\n\n---\n*ğŸ’¡ çµæ„Ÿæ¥æºæº¯æºï¼š*\n"
                for src in sources:
                    full_tweet += f"- ã€Š{src}ã€‹\n"
                    
                result_placeholder.markdown(full_tweet)
                st.success("âœ… ç­¾å‘å®Œæ¯•ï¼ä½ å¯ä»¥å¤åˆ¶ä¸Šæ–¹å¸¦æ„Ÿçš„å†…å®¹å’Œä¸­æ–‡ç›´æ¥å‘æ¨ã€‚å¦‚æœéœ€è¦é…å›¾ï¼ŒæŠŠæœ€ä¸‹æ–¹çš„è‹±æ–‡ Prompt æ‰”ç»™ Midjourney æˆ– Imagen å³å¯ã€‚")
                
            except Exception as e:
                st.error(f"ç”Ÿæˆå¤±è´¥ï¼š{e}")

if __name__ == "__main__":
    main()
