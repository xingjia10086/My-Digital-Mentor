import os
import json
import random
import lark_oapi as lark
from lark_oapi.api.im.v1 import *
from langchain_community.vectorstores import Chroma
from langchain_google_vertexai import VertexAIEmbeddings

# --- Configuration ---
FEISHU_APP_ID = "cli_a91397ee08f81bdb"
FEISHU_APP_SECRET = "J1FL9TPMD97NY8wu76FNGcZL4Y6PQ0AA"
# Use the precise open_id of the target user
TARGET_USER_ID = "ou_ef03183d5527e0efbf021ca2c1ea3228"

PROJECT_ID = "gen-lang-client-0834352502" 
LOCATION = "us-central1"
CHROMA_PERSIST_DIR = r"D:\GPT\AI-demo\chroma_db"
EMBEDDING_MODEL = "text-embedding-004"

print("=== åˆå§‹åŒ– æ˜Ÿä½³æ•°å­—å¯¼å¸ˆ (æ¯æ—¥çµæ„Ÿå¼•æ“) ===")

# 1. Initialize Clients
print("æ­£åœ¨è¿æ¥ æœ¬åœ° ChromaDB çŸ¥è¯†åº“...")
embeddings = VertexAIEmbeddings(
    model_name=EMBEDDING_MODEL,
    project=PROJECT_ID,
    location=LOCATION
)
vectorstore = Chroma(
    persist_directory=CHROMA_PERSIST_DIR,
    embedding_function=embeddings,
    collection_name="wechat_articles"
)
lark_client = lark.Client.builder().app_id(FEISHU_APP_ID).app_secret(FEISHU_APP_SECRET).build()


# 2. Randomly select a philosophical theme
themes = [
    "é•¿æœŸä¸»ä¹‰", "ç ´å±€", "æ‹’ç»å†…å·", "è®¤çŸ¥å‡çº§", "è´¢å¯Œè‡ªç”±", 
    "ç²¾åŠ›ç®¡ç†", "äººç”Ÿæˆ˜ç•¥", "é¦™æ¸¯èº«ä»½ä¸æ•™è‚²è§„åˆ’", "å­¤ç‹¬ä¸ç‹¬å¤„",
    "èŒåœºå‘ä¸Šç®¡ç†", "å•†ä¸šæ¨¡å¼", "å¦‚ä½•é¢å¯¹ç„¦è™‘"
]
selected_theme = random.choice(themes)
print(f"ä»Šæ—¥éšæœºæŠ½å–ä¸»é¢˜: ã€{selected_theme}ã€‘")

# 3. Retrieve a related insight from history
docs = vectorstore.similarity_search(selected_theme, k=1)
if not docs:
    print("çŸ¥è¯†åº“ä¸­æœªæ‰¾åˆ°ç›¸å…³ç‰‡æ®µã€‚")
    exit()

doc = docs[0]
source_file = doc.metadata.get('source_file', 'æœªçŸ¥æ–‡ç« ')
content_preview = doc.page_content.strip()

# Truncate content for the card if it's too long
if len(content_preview) > 300:
    content_preview = content_preview[:300] + "..."


# 4. Construct Feishu Rich Text Card (Message Card)
card_content = {
    "config": {
        "wide_screen_mode": True
    },
    "header": {
        "template": "blue",
        "title": {
            "content": "ğŸŒ… æ˜Ÿä½³çš„æ•°å­—å¤§è„‘ï¼šä»Šæ—¥é‡‘å¥æ¨é€",
            "tag": "plain_text"
        }
    },
    "elements": [
        {
            "tag": "div",
            "text": {
                "content": f"**ä»Šæ—¥ä¸»é¢˜**ï¼š{selected_theme}\n**å‡ºè‡ªæ–‡ç« **ï¼šã€Š{source_file}ã€‹\n\n\n**å½“å¹´ä½ æ˜¯è¿™ä¹ˆå†™çš„ï¼š**\n\n*{content_preview}*",
                "tag": "lark_md"
            }
        },
        {
            "tag": "hr"
        },
        {
            "tag": "note",
            "elements": [
                {
                    "content": "âœ¨ ä¿æŒä¸“æ³¨ï¼Œæ‹’ç»å†…å·ã€‚æ–°çš„ä¸€å¤©ï¼Œç ´å±€è€Œç”Ÿã€‚",
                    "tag": "lark_md"
                }
            ]
        }
    ]
}

# 5. Send Proactive Message
print(f"å‡†å¤‡å‘ç”¨æˆ· {TARGET_USER_ID} å‘é€é£ä¹¦å¡ç‰‡...")
# Notice: In a real scenario, you need the actual open_id, user_id, or email of the recipient.
# For testing, we will ask the user how they want to specify themselves.
request = CreateMessageRequest.builder() \
    .receive_id_type("open_id") \
    .request_body(CreateMessageRequestBody.builder()
        .receive_id(TARGET_USER_ID)
        .msg_type("interactive")
        .content(json.dumps(card_content))
        .build()) \
    .build()

response = lark_client.im.v1.message.create(request)

if response.success():
    print("âœ… æ¨é€æˆåŠŸï¼")
else:
    print(f"âŒ æ¨é€å¤±è´¥: {response.code}, {response.msg}")
