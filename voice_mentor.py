import os
import re
import subprocess
from google import genai
from langchain_google_vertexai import VertexAIEmbeddings
from langchain_community.vectorstores import Chroma

# --- Configuration ---
PROJECT_ID = "gen-lang-client-0834352502" 
LOCATION = "us-central1"
CHROMA_PERSIST_DIR = r"D:\GPT\AI-demo\chroma_db"
EMBEDDING_MODEL = "text-embedding-004"

API_KEY = "AIzaSyDuVkQKk3GH6MjS-bzIQgVkhSZ-utvwUBg"
client = genai.Client(api_key=API_KEY)


def format_docs(docs):
    formatted = []
    for d in docs:
        source = d.metadata.get('source_file', 'æœªçŸ¥æ–‡ç« ')
        formatted.append(f"ã€æ‘˜è‡ªæ–‡ç« ï¼šã€Š{source}ã€‹ã€‘\n{d.page_content}")
    return "\n\n---\n\n".join(formatted)

def clean_for_tts(text):
    """ç§»é™¤ Markdown ç­‰ä¼šå½±å“è¯­éŸ³æœ—è¯»çš„å¹²æ‰°å­—ç¬¦ï¼Œè®©è¯­éŸ³æ›´è‡ªç„¶ã€‚"""
    text = re.sub(r'[*_#`]', '', text)
    text = re.sub(r'\[.*?\]\(.*?\)', '', text) # ç§»é™¤é“¾æ¥
    text = text.replace('\n', 'ã€‚')
    # é™åˆ¶å•è¾¹è¯­éŸ³é•¿åº¦ï¼Œé˜²æ­¢ç”Ÿæˆå¤ªä¹…
    return text[:800] 

def speak_text(text):
    """è°ƒç”¨ edge-tts ç”Ÿæˆè¯­éŸ³å¹¶æ’­æ”¾ (Windows ä¸“ç”¨æ–¹æ¡ˆ)"""
    print("\n[å¯¼å¸ˆå‘å£°ä¸­... æ­£åœ¨ç”Ÿæˆè¯­éŸ³ğŸµ]")
    clean_txt = clean_for_tts(text)
    temp_file = "mentor_voice.mp3"
    
    # zh-CN-YunxiNeural: ç”·æ€§çŸ¥æ€§å£°éŸ³; zh-CN-XiaoxiaoNeural: å¥³æ€§å£°éŸ³
    cmd = f'edge-tts --text "{clean_txt}" --voice zh-CN-YunxiNeural --write-media {temp_file}'
    
    try:
        # Generate MP3
        subprocess.run(cmd, shell=True, check=True)
        # Play MP3 on Windows (will open default player or run silently depending on settings)
        # A lightweight cross-platform alternative if 'start' opens a big app is sometimes just to alert the user.
        print("\nâœ… è¯­éŸ³å·²ç”Ÿæˆï¼æ­£åœ¨ä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ’­æ”¾å™¨æ’­æ”¾...")
        os.system(f"start {temp_file}") 
    except Exception as e:
        print(f"è¯­éŸ³ç”Ÿæˆå¤±è´¥: {e}")

def main():
    print("=== åˆå§‹åŒ– æ˜Ÿä½³çš„æ•°å­—å¯¼å¸ˆå¤§è„‘ (ğŸ—£ï¸ è¯­éŸ³äº¤äº’ç‰ˆ) ===")
    
    if not os.path.exists(CHROMA_PERSIST_DIR):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æœ¬åœ°çŸ¥è¯†åº“ {CHROMA_PERSIST_DIR}ã€‚è¯·å…ˆè¿è¡Œ rag_ingest.py æ„å»ºçŸ¥è¯†åº“ã€‚")
        return
    
    chat_history = [] 
    MAX_HISTORY = 3 
    
    # Model Selection
    available = []
    for m in client.models.list():
        if 'gemini' in m.name.lower() and 'generate' in str(getattr(m, 'supported_actions', '')).lower():
            available.append(m.name)
            
    chosen_model = "gemini-2.0-flash"
    for preferred in ["gemini-2.5-pro", "gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"]:
        for a in available:
            if preferred in a:
                chosen_model = a
                break
        if chosen_model != "gemini-2.0-flash":
            break
            
    print(f"\n[ä½¿ç”¨æ¨¡å‹]: {chosen_model}")
    print(f"æ­£åœ¨åŠ è½½æœ¬åœ° ChromaDB...\n")
    
    embeddings = VertexAIEmbeddings(
        model_name=EMBEDDING_MODEL,
        project=PROJECT_ID,
        location=LOCATION
    )
    vectorstore = Chroma(
        persist_directory=CHROMA_PERSIST_DIR,
        embedding_function=embeddings,
        collection_name="wechat_articles"
    )
    
    # We use a smaller K here to ensure the TTS answer isn't overwhelmingly long or chaotic
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    print("\nâœ… è¯­éŸ³å¯¼å¸ˆå·²ä¸Šçº¿ã€‚è¾“å…¥ 'clear' æ¸…ç©ºè®°å¿†ï¼ŒæŒ‰ Ctrl+C é€€å‡ºã€‚\n")
    print("-" * 50)
    
    while True:
        try:
            user_input = input("\næœ‰ä»€ä¹ˆå›°æƒ‘ï¼Ÿè¯´æ¥å¬å¬ï¼š\n> ")
            if not user_input.strip():
                continue
            if user_input.lower() in ['exit', 'quit']:
                break
            if user_input.lower() == 'clear':
                chat_history = []
                print("\n[å¯¼å¸ˆ]: å¥½çš„ï¼Œæˆ‘å·²ç»æ¸…ç©ºäº†åˆšæ‰çš„å¯¹è¯è®°å¿†ï¼Œæˆ‘ä»¬é‡æ–°å¼€å§‹ã€‚")
                continue
                
            print("\n[å¯¼å¸ˆæ²‰æ€ä¸­... æ­£åœ¨æœç´¢ä½ çš„å†å²æ–‡ç« ]")
            
            search_query = user_input
            if chat_history:
                search_query = f"ç»“åˆè¯­å¢ƒ: {chat_history[-1]['q']} å¯¹äº {user_input} çš„æ¢è®¨"

            docs = retriever.invoke(search_query)
            context_str = format_docs(docs)
            
            history_str = ""
            if chat_history:
                history_str = "\nã€æœ€è¿‘çš„å¯¹è¯ã€‘ï¼š\n"
                for h in chat_history:
                    history_str += f"æ˜Ÿä½³: {h['q']}\nå¯¼å¸ˆ: {h['a'][:100]}...\n"
                    
            # Prompt tailored for voice delivery (short, punchy sentences)
            prompt = f"""ä½ æ˜¯æ˜Ÿä½³çš„æ•°å­—å…‹éš†ä½“ä¹Ÿæ˜¯ä»–çš„äººç”Ÿå¯¼å¸ˆã€‚
ç»“åˆå†å²æ–‡ç« ç‰‡æ®µï¼Œè§£ç­”ä»–å½“ä¸‹çš„å›°æƒ‘ã€‚

ã€æ³¨æ„è§„åˆ™ - è¿™æ˜¯ä¸ºäº†è¯­éŸ³åˆæˆå‡†å¤‡çš„å£è¯­åŒ–æ–‡æ¡ˆã€‘ï¼š
1. ä½ çš„å›ç­”å¿…é¡»éå¸¸**å£è¯­åŒ–ã€å£è¯­åŒ–ã€å£è¯­åŒ–**ï¼Œåƒè€æœ‹å‹åœ¨é¢å¯¹é¢èŠå¤©ï¼ˆä¸è¦ç”¨åˆ—æ¡ç›®ã€è¦ç‚¹123è¿™ç§ä¹¦é¢ç»“æ„ï¼‰ã€‚
2. æŠŠæ˜Ÿä½³æ›¾ç»çš„é‡‘å¥è‡ªç„¶åœ°è¯´å‡ºæ¥ï¼Œä»¿ä½›é‚£å°±æ˜¯ä½ éšå£æƒ³åˆ°çš„ã€‚
3. æŠŠå›ç­”æ§åˆ¶åœ¨ 150 å­—ä»¥å†…ï¼Œå­—æ•°è¶Šç²¾ç®€æœ‰åŠ›è¶Šå¥½ï¼Œå› ä¸ºè¦è½¬æˆè¯­éŸ³æœ—è¯»ï¼

{history_str}

ã€å†å²ç‰‡æ®µã€‘ï¼š
{context_str}

ã€æ˜Ÿä½³å½“å‰çš„å›°æƒ‘ã€‘ï¼š
{user_input}

ä½ çš„å›ç­” (è¯·ç›´æ¥ç»™å‡ºä¸€æ®µèƒ½ç›´æ¥æœ—è¯»çš„æµç•…å£è¯­å¯¹è¯)ï¼š"""

            print("\n[å¯¼å¸ˆçš„å›ç­”]:")
            full_response = ""
            for chunk in client.models.generate_content_stream(
                model=chosen_model,
                contents=prompt
            ):
                if chunk.text:
                    print(chunk.text, end="", flush=True)
                    full_response += chunk.text
            print("\n")
            
            # Text to Speech Generation & Play
            speak_text(full_response)
            
            # Update History
            chat_history.append({"q": user_input, "a": full_response})
            if len(chat_history) > MAX_HISTORY:
                chat_history.pop(0)

            print("-" * 50)
            
        except KeyboardInterrupt:
            print("\nå¯¼å¸ˆä¼‘æ¯äº†ã€‚å†è§ã€‚")
            break
        except Exception as e:
            print(f"\n[å‘ç”Ÿé”™è¯¯]: {e}")

if __name__ == "__main__":
    main()
