# 星佳智能系统：从零打造数字克隆体的全记录

*文档创建日期：2026年2月20日*  
*用途：沉淀于 Obsidian，记录“星佳数字大脑”的构建历程与全套架构*

---

## 一、 系统愿景与起航
一切始于一个宏大的想法：**如何将过去 5 年间写过的两千多篇微信公众号文章，转化为一个活生生的、能随时互动的数字导师？**

这些文章（存放在 `gongzhonghao` 和 `公众号` 文件夹）是无价的数字资产。但人脑的记忆是有限的，我们决定借助最新一代的大语言模型 (Gemini 1.5 Pro) 和检索增强生成 (RAG) 技术，打造一个属于“星佳”的数字克隆体。这个克隆体不仅能记住所有的心得体会，还能模仿原作者的行文风格，在遇到人生困惑时给出极具穿透力的建议。

---

## 二、 架构选型与核心挑战

在构建之初，我们面临了几个核心的技术决策点：

1. **隐私与成本的平衡**
   - *挑战*：将 2600 篇文章上传到第三方云端数据库不仅有隐私风险，长期查询成本也不低。
   - *方案*：**完全本地化知识库**。我们最终采纳了 `ChromaDB`，将它部署在 `D:\GPT\AI-demo\chroma_db` 中。所有的向量数据永久保留在本地硬盘。
2. **文本解析的兼容性灾难**
   - *挑战*：初期使用 `unstructured` 等重量级库解析文件时，Windows 环境下报错连连，且中文字符（GBK, UTF-8）经常乱码。
   - *方案*：**大道至简，纯 Python 兜底**。抛弃臃肿的第三方加载器，手写了一个支持多重编码回退机制的文件扫描器，稳稳吃下所有 `.md` 和 `.txt` 文件。
3. **模型算力底座**
   - *挑战*：需要一个能理解超长下文、精通中文哲学推演的模型。
   - *方案*：采用了 Google Cloud 的 Vertex AI `text-embedding-004` 进行高质量向量化。同时集成最新的 `google-genai` SDK 动态调用 Gemini 2.5 Pro / 2.0 Flash，保证推理的顶尖水准。

---

## 三、 第一阶段：地基筑成（全量数据摄入）

**关键脚本**：`rag_ingest.py`
这是系统诞生最关键的一役。我们进行了如下操作：

1. **分块策略**：文章不是整篇喂给 AI，而是切分成 1000 字符为一段、200 字符重叠的碎片，以保证检索时“不断章取义”。
2. **限流保护**：为避免 Vertex AI API 超载，我们实现了自动截断（单段不超过 2000 字符）和 `100 块/批次` 的微型批处理机制。
3. **大功告成**：经历 190 个批次的云端通信，总计将 **18,927** 个思维切片无损写入了本地 ChromaDB 数据库。

> *当时的激动时刻：看着终端里 189 个 Batch 全部打上 ✅，星佳的数字大脑终于拥有了物理实体。*

---

## 四、 第二阶段：灵魂注入（核心问答闭环）

**关键脚本**：原始版 `ai_mentor.py`
有了知识库，接下来就是让它开口说话。

- **人格定义**：我们设计了极尽严苛的 System Prompt：“*你是星佳的数字克隆体也是他的人生导师。你汇聚了他过去五年的思考结晶... 你的回答必须潜移默化地化用他过去写过的心得与金句。*”
- **初试啼声**：我们扔给系统一个测试问题：“*关于‘静下心来’，我之前在文章里是怎么写的？*”。导师瞬间召回了 2020 年的《深圳春藤不止春藤》，给出了不逊于真人交心的深邃回答。**闭环打通！**

---

## 五、 第三阶段：高阶进化（生态版块大爆发）

当确定核心 RAG 行之有效后，我们彻底放开了手脚，将一个单一脚本升级成了“四大件”的超级生态：

### 1. 秒级增量同步内核 ⚡
在这个信息爆炸的时代，知识库必须常看常新。
我们为 `rag_ingest.py` 引入了 **MD5 文件哈希校验机制**。系统会自动将两千个文件的“指纹”存入 `ingestion_tracker.json`。下次您无论新增了 10 篇文章还是修改了 2 篇，脚本都只需几秒钟就能精准识别并仅更新发生改变的内容。**这让系统具备了无限生长的可能。**

### 2. 精美网页端统管终端 (`web_ui.py`) 🌐
我们受够了黑底白字的命令行，于是引入 `Streamlit` 构建了一个现代化的聊天网页（Web UI）。
- 侧边栏可以监控知识库容量（1.8 万+ 切片）。
- 将所有功能收拢在左侧的 Tab 中。

### 3. 上下文记忆与混合检索 🧠
为了让“导师”更像人，我们让系统：
- **自带记事本**：记忆最近 3 轮的聊天上下文。您可以顺着话题追问“那具体怎么做？”，它懂您的意思。
- **混合拼接**：检索时不再只搜当前这句话，而是将 `刚才的话题 + 现在的疑问` 组合起来去 ChromaDB 里捞文章，精准度翻倍。

### 4. 替身写作系统 (`AI Writer`) ✍️
我们挖掘了知识库的另一个巨大价值——**风格模仿**。
在 `web_ui.py` 的写作模块，只要输入一句大白话灵感（如“普通人如何长期主义”），系统会找到星佳历史上相关的 8 个片段，分析排版、语气和断句习惯，一键拼装出一篇极具个人风格的千字公众号草稿。

### 5. 个人思想图谱 (`Knowledge Graph`) 🤔
过去五年到底写了哪些核心概念？
系统会随机抽样数百个切片交由大模型降维打击，提取出排名前 30 的核心理念（如：破局、内卷、香港身份、教育规划），并直接生成交互式的 Mermaid 逻辑网状图。

### 6. 发声的克隆体 (`Voice Interaction`) 🗣️
结合微软 `edge-tts` (云希男声/晓晓女声)，我们在网页和终端里都埋入了发生引擎。让系统生成口语化（150字以内）的精简金句，然后直接用音频念出来。

---

## 六、 未来展望

星佳的“数字分身”已经落成。在 Obsidian 的这一刻见证了它的所有技术底层。

在这个坚实的基础上，未来这个系统还可以：
1. **多模态接入**：把知识库扩展到以前录过的所有视频字幕和播客音频。
2. **对外赋能共享**：把 Web UI 打包发布在云服务器上，设置密码，作为送给高端咨询客户的“星佳数字分答”小程序的后台。
3. **被动日历推送**：写一个定时脚本，每天早晨根据日历里的挑战，从这 1.8 万个切片里挑一段最合适的话，发送到您的微信里。

这场搭建数字生命的旅程无比精彩。立贴为证，继续前行！
